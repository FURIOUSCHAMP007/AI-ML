{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (768, 9)\n",
      "\n",
      "First Few Rows:\n",
      "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0     6   148    72    35     0  33.6  0.627   50      1\n",
      "1     1    85    66    29     0  26.6  0.351   31      0\n",
      "2     8   183    64     0     0  23.3  0.672   32      1\n",
      "3     1    89    66    23    94  28.1  0.167   21      0\n",
      "4     0   137    40    35   168  43.1  2.288   33      1\n",
      "\n",
      "Average Accuracy (cross-validation): 0.7720437457279563\n",
      "\n",
      "Test Accuracy: 0.7359307359307359\n",
      "\n",
      "Feature importances from the Decision Tree classifier in Bagging model:\n",
      "[0.04585041 0.37355264 0.10363033 0.04155956 0.00861213 0.17702874\n",
      " 0.13604727 0.11371892]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#ENSEMBLE LEARN\n",
    "\n",
    "#Question 1 : Implement the Bagging based Ensemble Model using CART (Classification and Regression Trees) as base learners. \n",
    "#No. of base learners = 100. Use cross validation as the model estimation method.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define column names\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "# Load dataset from the local file\n",
    "df = pd.read_csv(\"pima-indians-diabetes.csv\", names=names)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst Few Rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.iloc[:, :-1].values  # All columns except the target\n",
    "Y = df.iloc[:, -1].values   # The target variable (class)\n",
    "\n",
    "# Cross-validation setup (10-fold cross-validation)\n",
    "Kfold = model_selection.KFold(n_splits=10, random_state=None)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "cart = DecisionTreeClassifier()\n",
    "\n",
    "# Create a Bagging classifier with Decision Trees as base estimator\n",
    "num_trees = 100  # Number of trees in the ensemble\n",
    "model = BaggingClassifier(estimator=cart, n_estimators=num_trees, random_state=7)\n",
    "\n",
    "# Perform cross-validation\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=Kfold)\n",
    "\n",
    "# Calculate the average accuracy\n",
    "average_accuracy = results.mean()\n",
    "\n",
    "# Print the average accuracy\n",
    "print(\"\\nAverage Accuracy (cross-validation):\", average_accuracy)\n",
    "\n",
    "# Train the model on the full dataset and evaluate on a separate test set\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3, random_state=7)\n",
    "\n",
    "# Train the Bagging model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "test_accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"\\nTest Accuracy:\", test_accuracy)\n",
    "\n",
    "# Optional: Train the Decision Tree classifier on the training data\n",
    "cart.fit(X_train, Y_train)  # Fit the Decision Tree classifier\n",
    "print(\"\\nFeature importances from the Decision Tree classifier in Bagging model:\")\n",
    "print(cart.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (768, 9)\n",
      "\n",
      "First Few Rows:\n",
      "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0     6   148    72    35     0  33.6  0.627   50      1\n",
      "1     1    85    66    29     0  26.6  0.351   31      0\n",
      "2     8   183    64     0     0  23.3  0.672   32      1\n",
      "3     1    89    66    23    94  28.1  0.167   21      0\n",
      "4     0   137    40    35   168  43.1  2.288   33      1\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.68831169 0.77922078 0.7012987  0.64935065 0.68831169 0.79220779\n",
      " 0.81818182 0.84415584 0.69736842 0.84210526]\n",
      "Average Cross-Validation Accuracy: 0.7500512645249489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FAIZAN AHMED\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.7489177489177489\n"
     ]
    }
   ],
   "source": [
    "#Question 2 : Implement the AdaBoost Ensemble model for classification using 10 base learners and cross validation.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define column names\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "# Load dataset from the local file\n",
    "df = pd.read_csv(\"pima-indians-diabetes.csv\", names=names)\n",
    "\n",
    "# Display dataset shape and first few rows\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst Few Rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.iloc[:, :-1].values  # All columns except the target\n",
    "Y = df.iloc[:, -1].values   # The target variable (class)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=7)\n",
    "\n",
    "# Create a Decision Tree classifier as the base learner\n",
    "base_learner = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Create an AdaBoost classifier with KNN as the base learner\n",
    "adaboost_model = AdaBoostClassifier(estimator=base_learner, n_estimators=10, random_state=7)\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores = cross_val_score(adaboost_model, X, Y, cv=10)\n",
    "\n",
    "# Print cross-validation accuracy\n",
    "print(\"\\nCross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Average Cross-Validation Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Train the AdaBoost model on the training set\n",
    "adaboost_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = adaboost_model.predict(X_test)\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"\\nTest Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (768, 9)\n",
      "\n",
      "First Few Rows:\n",
      "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0     6   148    72    35     0  33.6  0.627   50      1\n",
      "1     1    85    66    29     0  26.6  0.351   31      0\n",
      "2     8   183    64     0     0  23.3  0.672   32      1\n",
      "3     1    89    66    23    94  28.1  0.167   21      0\n",
      "4     0   137    40    35   168  43.1  2.288   33      1\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.66233766 0.68831169 0.68831169 0.66233766 0.72727273 0.76623377\n",
      " 0.75324675 0.75324675 0.69736842 0.71052632]\n",
      "Average Cross-Validation Accuracy: 0.7109193438140806\n",
      "\n",
      "Test Accuracy: 0.6796536796536796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Question 3: (Same as Question 1) Implement the Bagging based Ensemble Model using k-Nearest Neighbor Classifier as base learners. \n",
    "#No. of base learners = 100. Use cross validation as the model estimation method.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define column names\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "# Load dataset from the local file\n",
    "df = pd.read_csv(\"pima-indians-diabetes.csv\", names=names)\n",
    "\n",
    "# Display dataset shape and first few rows\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst Few Rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.iloc[:, :-1].values  # All columns except the target\n",
    "Y = df.iloc[:, -1].values   # The target variable (class)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=7)\n",
    "\n",
    "# Create a K-Nearest Neighbors classifier as the base learner\n",
    "base_learner = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Create a Bagging classifier with KNN as the base learner\n",
    "bagging_model = BaggingClassifier(estimator=base_learner, n_estimators=10, random_state=7)\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores = cross_val_score(bagging_model, X, Y, cv=10)\n",
    "\n",
    "# Print cross-validation accuracy\n",
    "print(\"\\nCross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Average Cross-Validation Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# Train the Bagging model on the training set\n",
    "bagging_model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = bagging_model.predict(X_test)\n",
    "\n",
    "# Evaluate the test accuracy\n",
    "test_accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"\\nTest Accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
